---
title: 最小2乗法で最ももっともらしい線が引けるわけ
published: 2019-12-26
tags:
  - 統計
---

実験なんかをしていると最小 2 乗法をよく使いますよね。ところでなぜ最小 2 乗法はうまい具合に近似線を引いてくれるのでしょうか。

## 最小 2 乗法

最小 2 乗法では、データ$[(x_1,y_1),..,(x_i,y_i),..,(x_N,y_N)]$が与えられたとき、

$$
\min \left\{ \sum^N_{i=1}(y_i-\hat{f}(x_i))^2 \right\}
$$

を満たす関数$\hat{f}$を求めます。すなわち、**残差平方和（residual sum of squares: RSS）**を最小化します。このようにして求めた$\hat{f}$は近似式としてもっともらしい関数になります。

では、一体なぜ残差平方和を最小化するのでしょうか。

## なぜ残差平方和を最小化するのか

試しに残差平方和を最小化する式を導出することを考えます。

### 因果関係の仮定

$x$と$y$の間に**因果関係を仮定**します。つまり、「$x$ならば$y$」なのか「$y$ならば$x$」なのかを区別する必要があります。因果の向きを逆転させる（$x$と$y$を入れ替える）と最小 2 乗法の結果も異なってしまいます。

ここで、最小 2 乗法は**因果関係の存在を示すものではない**ことにも注意が必要です。あくまで、もし因果関係があったらどうなるかを推定しているにすぎません。

### 最尤推定

「$x$ならば$y$」という因果関係を仮定することにします。ちなみに統計ではこのような$x$を**説明変数**、$y$を**目的変数**と呼びます。このとき、$y$を$x$で説明するモデル$f$を考えると、

$$
y = f(x;\theta) + \epsilon
$$

と表すことができます。ここで$\theta$はモデル$f$が持つパラメーターで、$\epsilon$は**誤差**を表します。

$\epsilon$が確率分布$p(\epsilon)$に従うとき、データ$\bm{d}=[(x_1,y_1),..,(x_i,y_i),..,(x_N,y_N)]$が得られる確率$P(\bm{d})$は、

$$
P(\bm{d}) = \prod^N_{i=1}p(\epsilon_i) = \prod^N_{i=1}p\left(y_i - f(x_i;\theta)\right)
$$

で書けます（このとき各データは互いに**独立**とします）。ここで考え方を変えて、データ$\bm{d}$が与えられたときのパラメーター$\theta$の関数$L(\theta|\bm{d})$を考えても、

$$
L(\theta|\bm{d}) = P(\bm{d}) = \prod^N_{i=1}p\left(y_i - f(x_i;\theta)\right)
$$

で書けます。この$L(\theta|\bm{d})$は[尤度](https://ja.wikipedia.org/wiki/%E5%B0%A4%E5%BA%A6%E9%96%A2%E6%95%B0)と呼ばれる値で、データ$\bm{d}$におけるパラメーター$\theta$の**尤もらしさ**（もっともらしさ）を表しています。この尤度を最大化するように、つまりもっとも尤もらしいパラメーター$\theta$を推定する手法を[最尤推定](https://ja.wikipedia.org/wiki/%E6%9C%80%E5%B0%A4%E6%8E%A8%E5%AE%9A)と言います。

ここで、尤もらしさとはあくまでデータ$\bm{d}$との適合度でしかないことには注意が必要です。つまり、尤度が最大であったとしても真のモデルとよく適合するとは限りません。データが真のモデルをよく表していなければ、最尤推定されるモデルも見当違いなものになってしまいます。

### 誤差分布の仮定

尤度$L(\theta|\bm{d})$を最大化するようなパラメーター$\hat{\theta}$を推定するには、誤差の確率分布$p(\epsilon)$が分かっていればよさそうです。そこで、ここでは確率分布として**平均 0 の正規分布**を仮定してみます。このとき、確率分布$p(\epsilon)$は、

$$
p(\epsilon) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left( -\frac{\epsilon^2}{2\sigma^2} \right)}
$$

で書けます。このとき、尤度$L(\theta|\bm{d})$は、

$$
\begin{aligned}
L(\theta|\bm{d}) &= \prod^N_{i=1} \frac{1}{\sqrt{2\pi\sigma_i^2}} \exp{\left( -\frac{(y_i - f(x_i;\theta))^2}{2\sigma_i^2} \right)} \\
&= \prod^N_{i=1} \frac{1}{\sqrt{2\pi\sigma_i^2}} \cdot \exp{\left( -\frac{1}{2}\sum^N_{i=1}\frac{(y_i - f(x_i;\theta))^2}{\sigma_i^2} \right)}
\end{aligned}
$$

となります。

### 最小 2 乗法へ

最後に尤度$L(\theta|\bm{d})$を最大化するようなパラメーター$\hat{\theta}$、つまり最尤推定されるモデル関数$\hat{f}$を求めていきます。いま誤差の分散$\sigma_i^2$が**一定**ならば、推定されるモデル関数$\hat{f}$は、

$$
\min \left\{ \sum^N_{i=1}(y_i - \hat{f}(x_i))^2 \right\}
$$

を満たすことが分かります。わお！残差平方和（RSS）の最小化を導くことができました！

まとめると、最小 2 乗法では"少なくとも"**目的変数の誤差分布が平均 0 分散一定の正規分布**であればもっとももっともらしいモデル関数を得られるってことです。

### 重み付き最小 2 乗法

ところで、誤差の分散$\sigma_i^2$が一定ではない場合は、

$$
\min \left\{ \sum^N_{i=1} \frac{(y_i - \hat{f}(x_i))^2}{\sigma_i^2} \right\}
$$

を最小化すれば良いことが分かります。これは**重み付き最小 2 乗法**と呼ばれるものです。つまり、誤差の分散が一定でない場合（データのばらつきが無視できない場合）は、通常の最小 2 乗法に$1/\sigma_i^2$の重みをつける必要があるということです。
